from langchain.chat_models import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.schema import Document, SystemMessage, HumanMessage
from dotenv import load_dotenv
import os
import sqlite3
from typing import List

from crud.chatbot import get_user_summary, save_user_summary, save_user_keywords
from models.user import User
from sqlalchemy.orm import Session

# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° LLM êµ¬ì„±
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
llm = ChatOpenAI(openai_api_key=openai_api_key, model_name="gpt-3.5-turbo", temperature=0)
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)

# ğŸœ prac.db ì‹ë‹¹ ë°ì´í„° ë¡œë”©
conn = sqlite3.connect("prac.db")
cursor = conn.cursor()
cursor.execute("SELECT id, name, address, phone, rating, latitude, longitude FROM restaurants")
rows = cursor.fetchall()

documents = []
for row in rows:
    id_, name, address, phone, rating, lat, lng = row
    menu_text = "ë©”ë‰´ ì •ë³´ ì—†ìŒ"
    content = f"""ì‹ë‹¹ëª…: {name}
ì£¼ì†Œ: {address}
ì „í™”ë²ˆí˜¸: {phone}
í‰ì : {rating}
ë©”ë‰´:
{menu_text}
"""
    documents.append(Document(
        page_content=content,
        metadata={"id": id_, "latitude": lat, "longitude": lng, "rating": rating}
    ))

docs = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100).split_documents(documents)
vectorstore = FAISS.from_documents(docs, embeddings)

# í‚¤ì›Œë“œ ì¶”ì¶œ
def extract_keywords_from_summary(summary: str) -> List[str]:
    messages = [
        SystemMessage(content="ë‹¤ìŒ ìš”ì•½ì—ì„œ ì‚¬ìš©ìì˜ ìŒì‹ ì·¨í–¥ì„ ë‚˜íƒ€ë‚´ëŠ” í•µì‹¬ í‚¤ì›Œë“œ 3~5ê°œë§Œ ì‰¼í‘œë¡œ ì¶”ì¶œí•´ì¤˜."),
        HumanMessage(content=summary)
    ]
    result = llm(messages).content.strip()
    return [kw.strip() for kw in result.split(",") if kw.strip()]

# ì˜ë„ ë¶„ë¥˜
def classify_intent(query: str, summary: str) -> str:
    messages = [
        SystemMessage(content="ë‹¤ìŒ ì§ˆë¬¸ì´ ìŒì‹ ì¶”ì²œ ì˜ë„ì¸ì§€ ëŒ€í™” ì˜ë„ì¸ì§€ íŒë‹¨í•´ì¤˜. ê²°ê³¼ëŠ” 'ì¶”ì²œ' ë˜ëŠ” 'ëŒ€í™”'ë¡œë§Œ ì‘ë‹µí•´."),
        HumanMessage(content=f"ìš”ì•½: {summary}\nì§ˆë¬¸: {query}")
    ]
    return llm(messages).content.strip()

# ë©”ì¸ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def generate_chat_response(user: User, message: str, db: Session):
    summary_obj = get_user_summary(db, user.id)
    summary = getattr(summary_obj, "summary", "")

    intent = classify_intent(message, summary)

    if intent != "ì¶”ì²œ":
        messages = [
            SystemMessage(content="ë„ˆëŠ” ìŒì‹ ì¶”ì²œ ì±—ë´‡ì´ì•¼. ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•´."),
            HumanMessage(content=message)
        ]
        result = llm(messages).content.strip()
        summary += f"\n[User]: {message}\n[Bot]: {result}"
        save_user_summary(db, user.id, summary)
        return {"response": result}

    # ì¶”ì²œ ìš”ì²­ ì²˜ë¦¬
    results = vectorstore.similarity_search(message, k=3)
    if not results:
        return {"response": "ì…ë ¥í•˜ì‹  ì •ë³´ë¡œëŠ” ì¶”ì²œí•  ìˆ˜ ìˆëŠ” ì‹ë‹¹ì´ ì—†ìŠµë‹ˆë‹¤. ìœ„ì¹˜ë‚˜ í‚¤ì›Œë“œë¥¼ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."}

    recommended = []
    for doc in results:
        lines = doc.page_content.strip().splitlines()
        name_line = next((line for line in lines if "ì‹ë‹¹ëª…:" in line), lines[0])
        recommended.append(f"ğŸ“ {name_line.strip()}")

    response_text = "\n".join(recommended)

    summary += f"\n[User]: {message}\n[Bot]: {response_text}"
    save_user_summary(db, user.id, summary)
    keywords = extract_keywords_from_summary(summary)
    save_user_keywords(db, user.id, keywords)

    return {"response": response_text}
